{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e51fd-414c-4189-83a5-96b9e45111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import time\n",
    "\n",
    "# Define paths and parameters\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "CLASSES = ['Closed_Eyes', 'Open_Eyes', 'No_yawn', 'Yawn']\n",
    "MODEL_PATH = ''  # Path to your saved model that you wants to use\n",
    "PREDICTOR_PATH = 'shape_predictor_68_face_landmarks.dat'  # dlib predictor\n",
    "MOUTH_ROI_SCALE = 1.5  # Scale factor to enlarge mouth ROI\n",
    "PADDING = 10  # Padding for eye ROIs to ensure sufficient size\n",
    "VIDEO_FPS = 20  # Assumed FPS for fatigue metric calculations\n",
    "\n",
    "# SEBlock function (from your model)\n",
    "def se_block(input_tensor, reduction=8):\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = tf.keras.layers.Reshape((1, 1, filters))(se)\n",
    "    se = tf.keras.layers.Dense(filters // reduction, activation='relu', use_bias=False)(se)\n",
    "    se = tf.keras.layers.Dense(filters, activation='sigmoid', use_bias=False)(se)\n",
    "    x = tf.keras.layers.Multiply()([input_tensor, se])\n",
    "    return x\n",
    "\n",
    "# Load the trained model and recompile to suppress warning\n",
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects={'se_block': se_block})\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Recompile to silence warning\n",
    "\n",
    "# Preprocess image for model input\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# Extract ROI using bounding box with padding\n",
    "def extract_roi(image, landmarks, points, is_mouth=False):\n",
    "    x_coords = [landmarks.part(i).x for i in points]\n",
    "    y_coords = [landmarks.part(i).y for i in points]\n",
    "    x_min, x_max = min(x_coords), max(x_coords)\n",
    "    y_min, y_max = min(y_coords), max(y_coords)\n",
    "    \n",
    "    if is_mouth:\n",
    "        # Scale the mouth ROI to make it larger\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        x_min = max(0, x_min - int(width * (MOUTH_ROI_SCALE - 1) / 2))\n",
    "        x_max = min(image.shape[1], x_max + int(width * (MOUTH_ROI_SCALE - 1) / 2))\n",
    "        y_min = max(0, y_min - int(height * (MOUTH_ROI_SCALE - 1) / 2))\n",
    "        y_max = min(image.shape[0], y_max + int(height * (MOUTH_ROI_SCALE - 1) / 2))\n",
    "    else:\n",
    "        # Add padding for eye ROIs to ensure sufficient size\n",
    "        x_min = max(0, x_min - PADDING)\n",
    "        x_max = min(image.shape[1], x_max + PADDING)\n",
    "        y_min = max(0, y_min - PADDING)\n",
    "        y_max = min(image.shape[0], y_max + PADDING)\n",
    "    \n",
    "    # Extract ROI\n",
    "    roi = image[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    if roi.size == 0:  # Handle empty ROI\n",
    "        return None, None\n",
    "    return roi, (int(x_min), int(y_min), int(x_max), int(y_max))\n",
    "\n",
    "# Predict drowsiness state\n",
    "def predict_drowsiness(roi, is_eye=True):\n",
    "    if roi is None:\n",
    "        return None, None\n",
    "    processed_roi = preprocess_image(roi)\n",
    "    prediction = model.predict(processed_roi, verbose=0)[0]\n",
    "    if is_eye:\n",
    "        pred_idx = np.argmax(prediction[:2])  # Only consider Closed_Eyes and Open_Eyes\n",
    "        return pred_idx, prediction[pred_idx]\n",
    "    else:\n",
    "        pred_idx = np.argmax(prediction[2:]) + 2  # Only consider No_yawn and Yawn\n",
    "        return pred_idx, prediction[pred_idx]\n",
    "\n",
    "# Process live video feed with fatigue metrics\n",
    "def process_live_video():\n",
    "    # Load detector and predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "    # Open webcam (default camera, usually index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open webcam.\")\n",
    "        return\n",
    "\n",
    "    # Initialize lists for tracking (based on 20 FPS)\n",
    "    list_B = np.ones(int(VIDEO_FPS * 3))  # Eye status for 3s (open=1, closed=0)\n",
    "    list_Y = np.zeros(int(VIDEO_FPS * 10))  # Mouth status for 10s (open=1, closed=0)\n",
    "    list_Y1 = np.ones(int(VIDEO_FPS * 1.5))  # Yawn pattern (1.5s open then close)\n",
    "    list_Y1[int(VIDEO_FPS * 1.5) - 1] = 0\n",
    "    list_blink = np.ones(int(VIDEO_FPS * 10))  # Blink status for 10s (blink=1, no blink=0)\n",
    "    list_yawn = np.zeros(int(VIDEO_FPS * 30))  # Yawn status for 30s (yawn=1, no yawn=0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        # Prepare frame\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        flag_B = False  # Eye closed flag (True if any eye is closed)\n",
    "        flag_Y = False  # Mouth open flag (True if mouth is Yawn)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            for face in faces:\n",
    "                landmarks = predictor(gray, face)\n",
    "\n",
    "                # Draw 68 landmarks on the frame\n",
    "                for n in range(68):\n",
    "                    x, y = landmarks.part(n).x, landmarks.part(n).y\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "                # Define landmark points\n",
    "                LEFT_EYE_POINTS = list(range(36, 42))  # Left eye landmarks (36-41)\n",
    "                RIGHT_EYE_POINTS = list(range(42, 48))  # Right eye landmarks (42-47)\n",
    "                MOUTH_POINTS = list(range(48, 68))  # Mouth landmarks (48-67)\n",
    "\n",
    "                # Extract ROIs\n",
    "                left_eye, left_eye_coords = extract_roi(frame_rgb, landmarks, LEFT_EYE_POINTS)\n",
    "                right_eye, right_eye_coords = extract_roi(frame_rgb, landmarks, RIGHT_EYE_POINTS)\n",
    "                mouth, mouth_coords = extract_roi(frame_rgb, landmarks, MOUTH_POINTS, is_mouth=True)\n",
    "\n",
    "                # Predict for eyes\n",
    "                if left_eye is not None:\n",
    "                    pred_idx, _ = predict_drowsiness(left_eye, is_eye=True)\n",
    "                    if pred_idx is not None and pred_idx == 0:  # Closed_Eyes\n",
    "                        flag_B = True\n",
    "                if right_eye is not None:\n",
    "                    pred_idx, _ = predict_drowsiness(right_eye, is_eye=True)\n",
    "                    if pred_idx is not None and pred_idx == 0:  # Closed_Eyes\n",
    "                        flag_B = True\n",
    "\n",
    "                # Predict for mouth\n",
    "                if mouth is not None:\n",
    "                    pred_idx, _ = predict_drowsiness(mouth, is_eye=False)\n",
    "                    if pred_idx is not None and pred_idx == 3:  # Yawn\n",
    "                        flag_Y = True\n",
    "\n",
    "                # Update lists\n",
    "                start_time = time.time()\n",
    "                if not flag_B:\n",
    "                    list_B = np.append(list_B, 1)  # Open eyes\n",
    "                else:\n",
    "                    list_B = np.append(list_B, 0)  # Closed eyes\n",
    "                list_B = np.delete(list_B, 0)\n",
    "\n",
    "                if flag_Y:\n",
    "                    list_Y = np.append(list_Y, 1)  # Open mouth\n",
    "                else:\n",
    "                    list_Y = np.append(list_Y, 0)  # Closed mouth\n",
    "                list_Y = np.delete(list_Y, 0)\n",
    "\n",
    "                # Detect blink (transition from open to closed)\n",
    "                if len(list_B) >= 2 and list_B[-2] == 1 and list_B[-1] == 0:\n",
    "                    list_blink = np.append(list_blink, 1)  # Blink detected\n",
    "                else:\n",
    "                    list_blink = np.append(list_blink, 0)  # No blink\n",
    "                list_blink = np.delete(list_blink, 0)\n",
    "\n",
    "                # Detect yawn (match list_Y1 pattern)\n",
    "                if len(list_Y) >= len(list_Y1) and (list_Y[-len(list_Y1):] == list_Y1).all():\n",
    "                    print('----------------------Yawn----------------------')\n",
    "                    list_Y = np.zeros(int(VIDEO_FPS * 10))  # Reset mouth status after yawn\n",
    "                    list_yawn = np.append(list_yawn, 1)  # Yawn detected\n",
    "                else:\n",
    "                    list_yawn = np.append(list_yawn, 0)  # No yawn\n",
    "                list_yawn = np.delete(list_yawn, 0)\n",
    "\n",
    "                # Calculate fatigue metrics\n",
    "                perclos = 1 - np.average(list_B)  # Percentage of time eyes are closed\n",
    "                perblink = np.average(list_blink)  # Average blink frequency\n",
    "                peryawn = np.average(list_yawn)  # Average yawn frequency\n",
    "\n",
    "                # Fatigue detection (thresholds from your code)\n",
    "                if perclos > 0.4 or perblink < 2.5 / (10 * VIDEO_FPS) or peryawn > 3 / (30 * VIDEO_FPS):\n",
    "                    fatigue_status = \"Fatigued\"\n",
    "                else:\n",
    "                    fatigue_status = \"Alert\"\n",
    "\n",
    "                # Draw ROIs and text\n",
    "                if left_eye_coords:\n",
    "                    cv2.rectangle(frame, (left_eye_coords[0], left_eye_coords[1]),\n",
    "                                 (left_eye_coords[2], left_eye_coords[3]), (255, 0, 0), 2)\n",
    "                if right_eye_coords:\n",
    "                    cv2.rectangle(frame, (right_eye_coords[0], right_eye_coords[1]),\n",
    "                                 (right_eye_coords[2], right_eye_coords[3]), (255, 0, 0), 2)\n",
    "                if mouth_coords:\n",
    "                    cv2.rectangle(frame, (mouth_coords[0], mouth_coords[1]),\n",
    "                                 (mouth_coords[2], mouth_coords[3]), (0, 0, 255), 2)\n",
    "\n",
    "                # Display predictions and metrics\n",
    "                left_eye_pred = predict_drowsiness(left_eye, is_eye=True)[0] if left_eye is not None else None\n",
    "                right_eye_pred = predict_drowsiness(right_eye, is_eye=True)[0] if right_eye is not None else None\n",
    "                mouth_pred = predict_drowsiness(mouth, is_eye=False)[0] if mouth is not None else None\n",
    "\n",
    "                left_eye_text = f\"Left Eye: {CLASSES[left_eye_pred] if left_eye_pred is not None else 'Not Detected'}\"\n",
    "                right_eye_text = f\"Right Eye: {CLASSES[right_eye_pred] if right_eye_pred is not None else 'Not Detected'}\"\n",
    "                mouth_text = f\"Mouth: {CLASSES[mouth_pred] if mouth_pred is not None else 'Not Detected'}\"\n",
    "                fps_text = f\"fps: {1 / (time.time() - start_time):.2f}\"\n",
    "                fatigue_text = f\"Status: {fatigue_status}\"\n",
    "\n",
    "                cv2.putText(frame, left_eye_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                cv2.putText(frame, right_eye_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                cv2.putText(frame, mouth_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                cv2.putText(frame, fps_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                cv2.putText(frame, fatigue_text, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Drowsiness Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_live_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
